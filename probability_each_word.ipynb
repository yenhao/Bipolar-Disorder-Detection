{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read execlusive file\n",
    "def ReadFileToDict(folder, filename, prefix = ''):\n",
    "    with open(folder + prefix + filename) as inputfile:\n",
    "        input_dict = {line.split('\\t')[0]:int(line.split('\\t')[1]) for line in inputfile.readlines()}   \n",
    "    return input_dict\n",
    "\n",
    "def tokens(str1): return re.findall('\\@?\\#?[a-zA-Z0-9]+\\'?[a-zA-Z0-9]+\\.*', str1)\n",
    "# to remove url\n",
    "def del_url(line): return re.sub(r'https?:\\/\\/.*', \"\", line)\n",
    "\n",
    "def checktag(list1): \n",
    "    ans_list = []\n",
    "    for item in list1:\n",
    "        if item[0] == '@':\n",
    "            item = '<user>'\n",
    "        elif item[0] == '#':\n",
    "            item = '#' + item[1:].lower()\n",
    "        else:\n",
    "            item = item.lower()\n",
    "        ans_list.append(item)\n",
    "    return ans_list\n",
    "\n",
    "def ReadOriginalData(filename):\n",
    "    sentence_list = []\n",
    "    with open('datasets/' + filename) as in_file:\n",
    "        for line in in_file.readlines():\n",
    "            user, content = line.split('\\t')\n",
    "            sentence_list.append(checktag(tokens(del_url(content))))\n",
    "    return sentence_list\n",
    "\n",
    "def wordCountInlist(in_list):\n",
    "    total_count = 0\n",
    "    for sentence_list in in_list:\n",
    "        sentence_list\n",
    "    return total_count\n",
    "\n",
    "def wordCountInDict(in_dict):\n",
    "    total_count = 0\n",
    "    for key in in_dict:\n",
    "        total_count += in_dict[key]\n",
    "    return total_count\n",
    "\n",
    "def normalizeByUserWord(original_file,exclusive_dict):\n",
    "    # create the user word dict first\n",
    "    userword_dict = defaultdict(lambda : defaultdict(lambda : 0))\n",
    "    with open('user_word_count/'+original_file+'.txt') as user_file:\n",
    "        for line in user_file.readlines():\n",
    "            userID, word, count = line.split('\\t')\n",
    "            userword_dict[word][userID] = int(count)\n",
    "    # Try to normalize each word\n",
    "    for word in exclusive_dict:\n",
    "        # if the word is in userword_dict\n",
    "        # do the normalize and change the value of exclusive_dict\n",
    "        # only count by how many user\n",
    "        if word in userword_dict:\n",
    "            exclusive_dict[word] = len(userword_dict[word])\n",
    "    return exclusive_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the file to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bipolar_experts BPD bipolar bb_mix regularUser_en_fixec\n",
    "filename = 'regularUser_en_fixed'\n",
    "\n",
    "file_dict = ReadFileToDict('WordCount/',filename+'.txt','result_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11013"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dict['shit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized by user word\n",
    "\n",
    "to eliminate the single user word dominated issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_dict = normalizeByUserWord(filename,file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dict['shit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the propability of each word been used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_word_count = wordCountInDict(file_dict)\n",
    "\n",
    "for word, count in file_dict.items():\n",
    "    file_dict[word] = count/total_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2772647"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001565291218103134"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dict['shit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('probabilityOfWord/'+filename,'w') as output_file:\n",
    "    for word, prob in sorted(file_dict.items(), key=operator.itemgetter(1), reverse = True):\n",
    "        output_file.write(\"{}\\t{}\\n\".format(word,str(prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
